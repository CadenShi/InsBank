{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "stage1 = torch.load('/mnt/public02/usr/yuanpeiwen/instruction_pool_cleaned/pool_evolve/ap_outputs/no_dolly_normal_order_multiply_alpha05_lambda_09_gamma1_ap_Alpaca.pth')\n",
    "stage2 = torch.load('/mnt/public02/usr/yuanpeiwen/instruction_pool_cleaned/pool_evolve/ap_outputs/no_dolly_normal_order_multiply_alpha05_lambda_09_gamma1_ap_ShareGPT.pth')\n",
    "stage3 = torch.load('/mnt/public02/usr/yuanpeiwen/instruction_pool_cleaned/pool_evolve/ap_outputs/no_dolly_normal_order_multiply_alpha05_lambda_09_gamma1_ap_WizardLM_alpaca.pth')\n",
    "stage4 = torch.load('/mnt/public02/usr/yuanpeiwen/instruction_pool_cleaned/pool_evolve/ap_outputs/no_dolly_normal_order_multiply_alpha05_lambda_09_gamma1_ap_WizardLM_sharegpt.pth')\n",
    "\n",
    "# stage1 = torch.load('/mnt/public02/usr/yuanpeiwen/instruction_pool_cleaned/baselines/deita_outputs/no_dolly_normal_order_sbs_deita_Alpaca.pth')\n",
    "# stage2 = torch.load('/mnt/public02/usr/yuanpeiwen/instruction_pool_cleaned/baselines/deita_outputs/no_dolly_normal_order_sbs_deita_ShareGPT.pth')\n",
    "# stage3 = torch.load('/mnt/public02/usr/yuanpeiwen/instruction_pool_cleaned/baselines/deita_outputs/no_dolly_normal_order_sbs_deita_WizardLM_alpaca.pth')\n",
    "# stage4 = torch.load('/mnt/public02/usr/yuanpeiwen/instruction_pool_cleaned/baselines/deita_outputs/no_dolly_normal_order_sbs_deita_WizardLM_sharegpt.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188.44916666666666\n",
      "244.36088419029312\n",
      "271.0185873605948\n",
      "270.4294405344149\n"
     ]
    }
   ],
   "source": [
    "len_stage1 = []\n",
    "for sample in stage1['data']:\n",
    "    conversatios = sample['conversations']\n",
    "    for turn in conversatios:\n",
    "        if turn['from'] in ['system', 'human', 'user']:\n",
    "            continue\n",
    "        len_stage1.append(len(turn['value'].strip().split(' ')))\n",
    "\n",
    "print(sum(len_stage1) / len(len_stage1))\n",
    "\n",
    "len_stage2 = []\n",
    "for sample in stage2['data']:\n",
    "    conversatios = sample['conversations']\n",
    "    for turn in conversatios:\n",
    "        if turn['from'] in ['system', 'human', 'user']:\n",
    "            continue\n",
    "        len_stage2.append(len(turn['value'].strip().split(' ')))\n",
    "\n",
    "print(sum(len_stage2) / len(len_stage2))\n",
    "\n",
    "len_stage3 = []\n",
    "for sample in stage3['data']:\n",
    "    conversatios = sample['conversations']\n",
    "    for turn in conversatios:\n",
    "        if turn['from'] in ['system', 'human', 'user']:\n",
    "            continue\n",
    "        len_stage3.append(len(turn['value'].strip().split(' ')))\n",
    "\n",
    "print(sum(len_stage3) / len(len_stage3))\n",
    "\n",
    "len_stage4 = []\n",
    "for sample in stage4['data']:\n",
    "    conversatios = sample['conversations']\n",
    "    for turn in conversatios:\n",
    "        if turn['from'] in ['system', 'human', 'user']:\n",
    "            continue\n",
    "        len_stage4.append(len(turn['value'].strip().split(' ')))\n",
    "print(sum(len_stage4) / len(len_stage4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_out_data_12 = []\n",
    "filtered_out_data_23 = []\n",
    "filtered_out_data_34 = []\n",
    "\n",
    "add_in_data_12 = []\n",
    "add_in_data_23 = []\n",
    "add_in_data_34 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_hash = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "stage1_no_tensor = []\n",
    "for sample in stage1['data']:\n",
    "    sample['idx'] = len(embedding_hash)\n",
    "    embedding_hash.append(sample['embedding'])\n",
    "    del sample['embedding']\n",
    "    stage1_no_tensor.append(sample)\n",
    "\n",
    "stage2_no_tensor = []\n",
    "for sample in stage2['data']:\n",
    "    sample['idx'] = len(embedding_hash)\n",
    "    embedding_hash.append(sample['embedding'])\n",
    "    del sample['embedding']\n",
    "    stage2_no_tensor.append(sample)\n",
    "\n",
    "stage3_no_tensor = []\n",
    "for sample in stage3['data']:\n",
    "    sample['idx'] = len(embedding_hash)\n",
    "    embedding_hash.append(sample['embedding'])\n",
    "    del sample['embedding']\n",
    "    stage3_no_tensor.append(sample)\n",
    "\n",
    "stage4_no_tensor = []\n",
    "for sample in stage4['data']:\n",
    "    sample['idx'] = len(embedding_hash)\n",
    "    embedding_hash.append(sample['embedding'])\n",
    "    del sample['embedding']\n",
    "    stage4_no_tensor.append(sample)\n",
    "\n",
    "\n",
    "for sample in stage1_no_tensor:\n",
    "    if sample not in stage2_no_tensor:\n",
    "        filtered_out_data_12.append(sample)\n",
    "for sample in stage2_no_tensor:\n",
    "    if sample not in stage1_no_tensor:\n",
    "        add_in_data_12.append(sample)\n",
    "\n",
    "for sample in stage2_no_tensor:\n",
    "    if sample not in stage3_no_tensor:\n",
    "        filtered_out_data_23.append(sample)\n",
    "for sample in stage3_no_tensor:\n",
    "    if sample not in stage2_no_tensor:\n",
    "        add_in_data_23.append(sample)\n",
    "\n",
    "for sample in stage3_no_tensor:\n",
    "    if sample not in stage4_no_tensor:\n",
    "        filtered_out_data_34.append(sample)\n",
    "for sample in stage4_no_tensor:\n",
    "    if sample not in stage3_no_tensor:\n",
    "        add_in_data_34.append(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(filtered_out_data_12)):\n",
    "    filtered_out_data_12[i]['embedding'] = embedding_hash[filtered_out_data_12[i]['idx']]\n",
    "    add_in_data_12[i]['embedding'] = embedding_hash[add_in_data_12[i]['idx']]\n",
    "for i in range(len(filtered_out_data_23)):   \n",
    "    filtered_out_data_23[i]['embedding'] = embedding_hash[filtered_out_data_23[i]['idx']]\n",
    "    add_in_data_23[i]['embedding'] = embedding_hash[add_in_data_23[i]['idx']]\n",
    "for i in range(len(filtered_out_data_34)):\n",
    "    filtered_out_data_34[i]['embedding'] = embedding_hash[filtered_out_data_34[i]['idx']]\n",
    "    add_in_data_34[i]['embedding'] = embedding_hash[add_in_data_34[i]['idx']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complexity: 1.951808860616201\n",
      "Quality: 4.403591043384498\n",
      "Instruction Len: 16.812833333333334\n",
      "Response Len: 188.44916666666666\n",
      "Complexity: 2.825256210936916\n",
      "Quality: 4.357931977857371\n",
      "Instruction Len: 291.2171636842078\n",
      "Response Len: 260.29975346450846\n"
     ]
    }
   ],
   "source": [
    "complexity = []\n",
    "quality = []\n",
    "instruction_len = []\n",
    "response_len = []\n",
    "for sample in filtered_out_data_12:\n",
    "    flag1 = False\n",
    "    flag2 = False\n",
    "    tmp_instruction_len = []\n",
    "    tmp_response_len = []\n",
    "    conversations = sample['conversations']\n",
    "    for turn in conversations:\n",
    "        if turn['from'] == 'system':\n",
    "            continue\n",
    "        if turn['from'] in ['human', 'user']:\n",
    "            tmp_instruction_len.append(len(turn['value'].strip().split(' ')))\n",
    "            flag2 = True\n",
    "        else:\n",
    "            tmp_response_len.append(len(turn['value'].strip().split(' ')))\n",
    "            flag1 = True\n",
    "    if flag1 and flag2:\n",
    "        complexity.append(sample['complexity'])\n",
    "        quality.append(sample['quality'])\n",
    "        instruction_len.append(sum(tmp_instruction_len)/len(tmp_instruction_len))\n",
    "        response_len.append(sum(tmp_response_len)/len(tmp_response_len))\n",
    "print(f'Complexity: {sum(complexity)/len(complexity)}')\n",
    "print(f'Quality: {sum(quality)/len(quality)}')\n",
    "print(f'Instruction Len: {sum(instruction_len)/len(instruction_len)}')\n",
    "print(f'Response Len: {sum(response_len)/len(response_len)}')\n",
    "\n",
    "complexity = []\n",
    "quality = []\n",
    "instruction_len = []\n",
    "response_len = []\n",
    "for sample in add_in_data_12:\n",
    "    flag1 = False\n",
    "    flag2 = False\n",
    "    tmp_instruction_len = []\n",
    "    tmp_response_len = []\n",
    "    conversations = sample['conversations']\n",
    "    for turn in conversations:\n",
    "        if turn['from'] == 'system':\n",
    "            continue\n",
    "        if turn['from'] in ['human', 'user']:\n",
    "            tmp_instruction_len.append(len(turn['value'].strip().split(' ')))\n",
    "            flag2 = True\n",
    "        else:\n",
    "            tmp_response_len.append(len(turn['value'].strip().split(' ')))\n",
    "            flag1 = True\n",
    "    if flag1 and flag2:\n",
    "        complexity.append(sample['complexity'])\n",
    "        quality.append(sample['quality'])\n",
    "        instruction_len.append(sum(tmp_instruction_len)/len(tmp_instruction_len))\n",
    "        response_len.append(sum(tmp_response_len)/len(tmp_response_len))\n",
    "print(f'Complexity: {sum(complexity)/len(complexity)}')\n",
    "print(f'Quality: {sum(quality)/len(quality)}')\n",
    "print(f'Instruction Len: {sum(instruction_len)/len(instruction_len)}')\n",
    "print(f'Response Len: {sum(response_len)/len(response_len)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complexity: 2.825256210936916\n",
      "Quality: 4.357931977857371\n",
      "Instruction Len: 291.2171636842078\n",
      "Response Len: 260.29975346450846\n",
      "Complexity: 4.015326088705995\n",
      "Quality: 4.606013654295061\n",
      "Instruction Len: 275.6666785972795\n",
      "Response Len: 299.96230599484863\n"
     ]
    }
   ],
   "source": [
    "complexity = []\n",
    "quality = []\n",
    "instruction_len = []\n",
    "response_len = []\n",
    "for sample in filtered_out_data_23:\n",
    "    flag1 = False\n",
    "    flag2 = False\n",
    "    tmp_instruction_len = []\n",
    "    tmp_response_len = []\n",
    "    conversations = sample['conversations']\n",
    "    for turn in conversations:\n",
    "        if turn['from'] == 'system':\n",
    "            continue\n",
    "        if turn['from'] in ['human', 'user']:\n",
    "            tmp_instruction_len.append(len(turn['value'].strip().split(' ')))\n",
    "            flag2 = True\n",
    "        else:\n",
    "            tmp_response_len.append(len(turn['value'].strip().split(' ')))\n",
    "            flag1 = True\n",
    "    if flag1 and flag2:\n",
    "        complexity.append(sample['complexity'])\n",
    "        quality.append(sample['quality'])\n",
    "        instruction_len.append(sum(tmp_instruction_len)/len(tmp_instruction_len))\n",
    "        response_len.append(sum(tmp_response_len)/len(tmp_response_len))\n",
    "print(f'Complexity: {sum(complexity)/len(complexity)}')\n",
    "print(f'Quality: {sum(quality)/len(quality)}')\n",
    "print(f'Instruction Len: {sum(instruction_len)/len(instruction_len)}')\n",
    "print(f'Response Len: {sum(response_len)/len(response_len)}')\n",
    "\n",
    "complexity = []\n",
    "quality = []\n",
    "instruction_len = []\n",
    "response_len = []\n",
    "for sample in add_in_data_23:\n",
    "    flag1 = False\n",
    "    flag2 = False\n",
    "    tmp_instruction_len = []\n",
    "    tmp_response_len = []\n",
    "    conversations = sample['conversations']\n",
    "    for turn in conversations:\n",
    "        if turn['from'] == 'system':\n",
    "            continue\n",
    "        if turn['from'] in ['human', 'user']:\n",
    "            tmp_instruction_len.append(len(turn['value'].strip().split(' ')))\n",
    "            flag2 = True\n",
    "        else:\n",
    "            tmp_response_len.append(len(turn['value'].strip().split(' ')))\n",
    "            flag1 = True\n",
    "    if flag1 and flag2:\n",
    "        complexity.append(sample['complexity'])\n",
    "        quality.append(sample['quality'])\n",
    "        instruction_len.append(sum(tmp_instruction_len)/len(tmp_instruction_len))\n",
    "        response_len.append(sum(tmp_response_len)/len(tmp_response_len))\n",
    "print(f'Complexity: {sum(complexity)/len(complexity)}')\n",
    "print(f'Quality: {sum(quality)/len(quality)}')\n",
    "print(f'Instruction Len: {sum(instruction_len)/len(instruction_len)}')\n",
    "print(f'Response Len: {sum(response_len)/len(response_len)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complexity: 4.015326088705995\n",
      "Quality: 4.606013654295061\n",
      "Instruction Len: 275.6666785972795\n",
      "Response Len: 299.96230599484863\n",
      "Complexity: 4.295817918055113\n",
      "Quality: 4.70867566511273\n",
      "Instruction Len: 307.42572071904686\n",
      "Response Len: 295.5129821769998\n"
     ]
    }
   ],
   "source": [
    "complexity = []\n",
    "quality = []\n",
    "instruction_len = []\n",
    "response_len = []\n",
    "for sample in filtered_out_data_34:\n",
    "    flag1 = False\n",
    "    flag2 = False\n",
    "    tmp_instruction_len = []\n",
    "    tmp_response_len = []\n",
    "    conversations = sample['conversations']\n",
    "    for turn in conversations:\n",
    "        if turn['from'] == 'system':\n",
    "            continue\n",
    "        if turn['from'] in ['human', 'user']:\n",
    "            tmp_instruction_len.append(len(turn['value'].strip().split(' ')))\n",
    "            flag2 = True\n",
    "        else:\n",
    "            tmp_response_len.append(len(turn['value'].strip().split(' ')))\n",
    "            flag1 = True\n",
    "    if flag1 and flag2:\n",
    "        complexity.append(sample['complexity'])\n",
    "        quality.append(sample['quality'])\n",
    "        instruction_len.append(sum(tmp_instruction_len)/len(tmp_instruction_len))\n",
    "        response_len.append(sum(tmp_response_len)/len(tmp_response_len))\n",
    "print(f'Complexity: {sum(complexity)/len(complexity)}')\n",
    "print(f'Quality: {sum(quality)/len(quality)}')\n",
    "print(f'Instruction Len: {sum(instruction_len)/len(instruction_len)}')\n",
    "print(f'Response Len: {sum(response_len)/len(response_len)}')\n",
    "\n",
    "complexity = []\n",
    "quality = []\n",
    "instruction_len = []\n",
    "response_len = []\n",
    "for sample in add_in_data_34:\n",
    "    flag1 = False\n",
    "    flag2 = False\n",
    "    tmp_instruction_len = []\n",
    "    tmp_response_len = []\n",
    "    conversations = sample['conversations']\n",
    "    for turn in conversations:\n",
    "        if turn['from'] == 'system':\n",
    "            continue\n",
    "        if turn['from'] in ['human', 'user']:\n",
    "            tmp_instruction_len.append(len(turn['value'].strip().split(' ')))\n",
    "            flag2 = True\n",
    "        else:\n",
    "            tmp_response_len.append(len(turn['value'].strip().split(' ')))\n",
    "            flag1 = True\n",
    "    if flag1 and flag2:\n",
    "        complexity.append(sample['complexity'])\n",
    "        quality.append(sample['quality'])\n",
    "        instruction_len.append(sum(tmp_instruction_len)/len(tmp_instruction_len))\n",
    "        response_len.append(sum(tmp_response_len)/len(tmp_response_len))\n",
    "print(f'Complexity: {sum(complexity)/len(complexity)}')\n",
    "print(f'Quality: {sum(quality)/len(quality)}')\n",
    "print(f'Instruction Len: {sum(instruction_len)/len(instruction_len)}')\n",
    "print(f'Response Len: {sum(response_len)/len(response_len)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered out 12: quality: 4.403591043384498 -- complexity: 1.951808860616201 -- avg similarity: 0.752318799495697 -- avg nearest neighbour similarity: 0.8985397219657898\n",
      "Add in 12: quality: 4.357931977857371 -- complexity: 2.825256210936916 -- avg similarity: 0.5447814464569092 -- avg nearest neighbour similarity: 0.82834792137146\n"
     ]
    }
   ],
   "source": [
    "embeddings = torch.cat([item['embedding'].unsqueeze(0) for item in filtered_out_data_12], dim=0).cuda()\n",
    "\n",
    "similarity_matrix = torch.zeros((embeddings.size(0), embeddings.size(0)))\n",
    "batch_size = 1  # 可以根据显存大小调整\n",
    "\n",
    "# 逐批计算\n",
    "for i in range(0, embeddings.size(0), batch_size):\n",
    "    end_i = i + batch_size\n",
    "    batch_i = embeddings[i:end_i]\n",
    "    similarity = F.cosine_similarity(batch_i.unsqueeze(1), embeddings.unsqueeze(0), dim=-1)\n",
    "    similarity_matrix[i:end_i, :] = similarity\n",
    "\n",
    "mask = torch.ones(similarity_matrix.shape, dtype=bool)\n",
    "mask.fill_diagonal_(0)\n",
    "filtered_similarity = similarity_matrix.masked_select(mask).view(embeddings.size(0), -1)\n",
    "nn_sim = filtered_similarity.max(dim=1).values\n",
    "quality = [item['quality'] for item in filtered_out_data_12]\n",
    "complexity = [item['complexity'] for item in filtered_out_data_12]\n",
    "print(f\"Filtered out 12: quality: {sum(quality) / len(quality)} -- complexity: {sum(complexity) / len(complexity)} -- avg similarity: {filtered_similarity.mean()} -- avg nearest neighbour similarity: {nn_sim.mean()}\")\n",
    "\n",
    "embeddings = torch.cat([item['embedding'].unsqueeze(0) for item in add_in_data_12], dim=0).cuda()\n",
    "\n",
    "similarity_matrix = torch.zeros((embeddings.size(0), embeddings.size(0)))\n",
    "batch_size = 1  # 可以根据显存大小调整\n",
    "\n",
    "# 逐批计算\n",
    "for i in range(0, embeddings.size(0), batch_size):\n",
    "    end_i = i + batch_size\n",
    "    batch_i = embeddings[i:end_i]\n",
    "    similarity = F.cosine_similarity(batch_i.unsqueeze(1), embeddings.unsqueeze(0), dim=-1)\n",
    "    similarity_matrix[i:end_i, :] = similarity\n",
    "\n",
    "mask = torch.ones(similarity_matrix.shape, dtype=bool)\n",
    "mask.fill_diagonal_(0)\n",
    "filtered_similarity = similarity_matrix.masked_select(mask).view(embeddings.size(0), -1)\n",
    "nn_sim = filtered_similarity.max(dim=1).values\n",
    "quality = [item['quality'] for item in add_in_data_12]\n",
    "complexity = [item['complexity'] for item in add_in_data_12]\n",
    "print(f\"Add in 12: quality: {sum(quality) / len(quality)} -- complexity: {sum(complexity) / len(complexity)} -- avg similarity: {filtered_similarity.mean()} -- avg nearest neighbour similarity: {nn_sim.mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered out 23: quality: 4.357931977857371 -- complexity: 2.825256210936916 -- avg similarity: 0.5447814464569092 -- avg nearest neighbour similarity: 0.82834792137146\n",
      "Add in 23: quality: 4.606013654295061 -- complexity: 4.015326088705995 -- avg similarity: 0.5823290944099426 -- avg nearest neighbour similarity: 0.83968186378479\n"
     ]
    }
   ],
   "source": [
    "embeddings = torch.cat([item['embedding'].unsqueeze(0) for item in filtered_out_data_23], dim=0).cuda()\n",
    "\n",
    "similarity_matrix = torch.zeros((embeddings.size(0), embeddings.size(0)))\n",
    "batch_size = 1  # 可以根据显存大小调整\n",
    "\n",
    "# 逐批计算\n",
    "for i in range(0, embeddings.size(0), batch_size):\n",
    "    end_i = i + batch_size\n",
    "    batch_i = embeddings[i:end_i]\n",
    "    similarity = F.cosine_similarity(batch_i.unsqueeze(1), embeddings.unsqueeze(0), dim=-1)\n",
    "    similarity_matrix[i:end_i, :] = similarity\n",
    "\n",
    "mask = torch.ones(similarity_matrix.shape, dtype=bool)\n",
    "mask.fill_diagonal_(0)\n",
    "filtered_similarity = similarity_matrix.masked_select(mask).view(embeddings.size(0), -1)\n",
    "nn_sim = filtered_similarity.max(dim=1).values\n",
    "quality = [item['quality'] for item in filtered_out_data_23]\n",
    "complexity = [item['complexity'] for item in filtered_out_data_23]\n",
    "print(f\"Filtered out 23: quality: {sum(quality) / len(quality)} -- complexity: {sum(complexity) / len(complexity)} -- avg similarity: {filtered_similarity.mean()} -- avg nearest neighbour similarity: {nn_sim.mean()}\")\n",
    "\n",
    "embeddings = torch.cat([item['embedding'].unsqueeze(0) for item in add_in_data_23], dim=0).cuda()\n",
    "\n",
    "similarity_matrix = torch.zeros((embeddings.size(0), embeddings.size(0)))\n",
    "batch_size = 1  # 可以根据显存大小调整\n",
    "\n",
    "# 逐批计算\n",
    "for i in range(0, embeddings.size(0), batch_size):\n",
    "    end_i = i + batch_size\n",
    "    batch_i = embeddings[i:end_i]\n",
    "    similarity = F.cosine_similarity(batch_i.unsqueeze(1), embeddings.unsqueeze(0), dim=-1)\n",
    "    similarity_matrix[i:end_i, :] = similarity\n",
    "\n",
    "mask = torch.ones(similarity_matrix.shape, dtype=bool)\n",
    "mask.fill_diagonal_(0)\n",
    "filtered_similarity = similarity_matrix.masked_select(mask).view(embeddings.size(0), -1)\n",
    "nn_sim = filtered_similarity.max(dim=1).values\n",
    "quality = [item['quality'] for item in add_in_data_23]\n",
    "complexity = [item['complexity'] for item in add_in_data_23]\n",
    "print(f\"Add in 23: quality: {sum(quality) / len(quality)} -- complexity: {sum(complexity) / len(complexity)} -- avg similarity: {filtered_similarity.mean()} -- avg nearest neighbour similarity: {nn_sim.mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered out 34: quality: 4.606013654295061 -- complexity: 4.015326088705995 -- avg similarity: 0.5823290944099426 -- avg nearest neighbour similarity: 0.83968186378479\n",
      "Add in 34: quality: 4.70867566511273 -- complexity: 4.295817918055113 -- avg similarity: 0.557906985282898 -- avg nearest neighbour similarity: 0.8309535384178162\n"
     ]
    }
   ],
   "source": [
    "embeddings = torch.cat([item['embedding'].unsqueeze(0) for item in filtered_out_data_34], dim=0).cuda()\n",
    "\n",
    "similarity_matrix = torch.zeros((embeddings.size(0), embeddings.size(0)))\n",
    "batch_size = 1  # 可以根据显存大小调整\n",
    "\n",
    "# 逐批计算\n",
    "for i in range(0, embeddings.size(0), batch_size):\n",
    "    end_i = i + batch_size\n",
    "    batch_i = embeddings[i:end_i]\n",
    "    similarity = F.cosine_similarity(batch_i.unsqueeze(1), embeddings.unsqueeze(0), dim=-1)\n",
    "    similarity_matrix[i:end_i, :] = similarity\n",
    "\n",
    "mask = torch.ones(similarity_matrix.shape, dtype=bool)\n",
    "mask.fill_diagonal_(0)\n",
    "filtered_similarity = similarity_matrix.masked_select(mask).view(embeddings.size(0), -1)\n",
    "nn_sim = filtered_similarity.max(dim=1).values\n",
    "quality = [item['quality'] for item in filtered_out_data_34]\n",
    "complexity = [item['complexity'] for item in filtered_out_data_34]\n",
    "print(f\"Filtered out 34: quality: {sum(quality) / len(quality)} -- complexity: {sum(complexity) / len(complexity)} -- avg similarity: {filtered_similarity.mean()} -- avg nearest neighbour similarity: {nn_sim.mean()}\")\n",
    "\n",
    "embeddings = torch.cat([item['embedding'].unsqueeze(0) for item in add_in_data_34], dim=0).cuda()\n",
    "\n",
    "similarity_matrix = torch.zeros((embeddings.size(0), embeddings.size(0)))\n",
    "batch_size = 1  # 可以根据显存大小调整\n",
    "\n",
    "# 逐批计算\n",
    "for i in range(0, embeddings.size(0), batch_size):\n",
    "    end_i = i + batch_size\n",
    "    batch_i = embeddings[i:end_i]\n",
    "    similarity = F.cosine_similarity(batch_i.unsqueeze(1), embeddings.unsqueeze(0), dim=-1)\n",
    "    similarity_matrix[i:end_i, :] = similarity\n",
    "\n",
    "mask = torch.ones(similarity_matrix.shape, dtype=bool)\n",
    "mask.fill_diagonal_(0)\n",
    "filtered_similarity = similarity_matrix.masked_select(mask).view(embeddings.size(0), -1)\n",
    "nn_sim = filtered_similarity.max(dim=1).values\n",
    "quality = [item['quality'] for item in add_in_data_34]\n",
    "complexity = [item['complexity'] for item in add_in_data_34]\n",
    "print(f\"Add in 34: quality: {sum(quality) / len(quality)} -- complexity: {sum(complexity) / len(complexity)} -- avg similarity: {filtered_similarity.mean()} -- avg nearest neighbour similarity: {nn_sim.mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
